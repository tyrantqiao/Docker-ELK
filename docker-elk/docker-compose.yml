version: '3.6'
services:
  filebeat:
    image: docker.elastic.co/beats/filebeat:6.3.1
    container_name: filebeat
    command: --strict.perms=false -e
    #当无法启动filebeat检查是否传对参数，重要的是将日志存放地址替换掉filebeat中地址
    user: root
    volumes:
      - /etc/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /etc/logs/:/home/logs
    networks: ['stack']
    healthcheck:
      test: filebeat test config
      interval: 30s
      timeout: 15s
      retries: 5    
  
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    networks: ['stack']
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    networks: ['stack']
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.16.11.119
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_BROKER_ID: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.3.1
    container_name: elasticsearch
    ports:
      - "9200:9200"
    networks: ['stack']
    volumes:
      - /etc/elk/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    healthcheck:
      test: curl --cacert /usr/share/elasticsearch/config/certs/ca/ca.crt -s https://localhost:9200 >/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
      interval: 30s
      timeout: 10s
      retries: 5

  elasticsearch2:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.3.1
    container_name: elasticsearch2
    ports:
      - "9201:9201"
    networks: ['stack']
    depends_on: ['elasticsearch']
    volumes:
      - /etc/elk/config/elasticsearch2.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    healthcheck:
      test: curl --cacert /usr/share/elasticsearch/config/certs/ca/ca.crt -s https://localhost:9201 >/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
      interval: 30s
      timeout: 10s
      retries: 5


  logstash:
    image: docker.elastic.co/logstash/logstash:6.3.1
    container_name: logstash
    networks: ['stack']
    depends_on: ['elasticsearch','elasticsearch2']
    volumes:
      - /etc/logstash/logstash.yml:/usr/share/logstash/logstash.yml
      - /etc/logstash/conf.d/demo.conf:/usr/share/logstash/pipeline/logstash.conf
      - /etc/logstash/patterns:/etc/logstash/patterns
    healthcheck:
      test: bin/logstash -t
      interval: 60s
      timeout: 50s
      retries: 5

  #logstash2:
  #  image: docker.elastic.co/logstash/logstash:6.3.1
  #  container_name: logstash2
  #  networks: ['stack']
  #  depends_on: ['elasticsearch']
  #  volumes:
  #    - /etc/logstash/logstash.yml:/usr/share/logstash/logstash.yml
  #    - /etc/logstash/conf.d/demo.conf:/usr/share/logstash/pipeline/logstash.conf
  #    - /etc/logstash/patterns:/etc/logstash/patterns
  #  healthcheck:
  #    test: bin/logstash -t
  #    interval: 60s
  #    timeout: 50s
  #    retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:6.3.1
    container_name: kibana
    ports:
      - "5601:5601"
    networks: ['stack']
    depends_on: ['elasticsearch','elasticsearch2']
    user: root
    volumes:
      - /etc/elk/config/kibana.yml:/usr/share/kibana/config/kibana.yml
    environment:
      XPACK_MONITORING_COLLECTION_ENABLED: "true"

networks: {stack: {}}
