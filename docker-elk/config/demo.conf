input{
  kafka{
    #bootstrap_servers => "localhost:9092,localhost:9093,localhost:9094"
    #看你在filebeat中设置的topic是什么
    bootstrap_servers => "172.16.11.119:9092"
    #topics => ["im","permission","thirdapi","casecenter","archivecenter","interrogate","faceapi","cloudconfig","eureka"]
    topics => ["huadu","huangpu","linhe","nanshan","zengcheng"]
    consumer_threads => 6
    group_id => "logstash-group1"
    codec=>"json"
  }
  
}

filter{
  grok{
    patterns_dir => ["/etc/logstash/patterns"]
    match => {"message" => "\s*%{TIMESTAMP_ISO8601:time}\s*%{LOGLEVEL:loglevel}\s*[0-9]{2}\s*---\s*\[\s*%{RUNNING_THREAD:thread}\] %{CLASS:class}\s*:\s* %{MSG:msg}"}
  }
  mutate {
    remove_field=>["beat","message","input"]
    gsub => ["message","\\n","
"]}
}

output{
  elasticsearch {
    #发布给elasticsearch的server
    hosts => ['172.16.11.119:9200']
    #hosts => ['elasticsearch']
    #设置index，用于告诉kibana这个output的东西叫什么名字
    index => "log-%{+YYYY.MM.dd}"
    #index => "%{topics}-%{+YYYY.MM.dd}-log"
  }
}
